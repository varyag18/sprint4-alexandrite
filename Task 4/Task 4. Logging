Анализ системы и планирование логирования

1.1 Нам требуются логи от всех ключевых узлов:

    Shop API (SpringBoot). Логи о входящих HTTP-запросах (REST) от Internet Shop, загрузке 3D-файлов, взаимодействии с Shop DB.
    CRM API (SpringBoot). Логи о статусах заказов, отправке и получении сообщений из RabbitMQ, чтении/записи в 3D Files Storage.
    MES API (C#). Логи о расчёте стоимости, взаимодействии с MES DB, отправке и получении сообщений из RabbitMQ.
    RabbitMQ. Логирование сообщений о подключениях, а также метаданных: кто подключён, какие очереди, объём очередей, ошибки при ack/nack.
    Shop DB, MES DB. Обычно системные логи СУБД и журнал запросов (queries). Однако зачастую достаточно логов на уровне приложений (Shop API, MES API), которые фиксируют SQL-запросы.
    3D Files Storage (S3-based). Запись действий (PUT/GET), особенно если возникают ошибки доступа.

На диаграмме выделены синим (blue) все контейнеры, откуда собираются логи: Shop API, CRM API, MES API, RabbitMQ, DB и 3D-хранилище.

1.2 Список необходимых логов уровня INFO

События, которые нужно логировать на уровне INFO (в дополнение к стандартным HTTP-логам, которые обычно пишутся на уровне middleware):

    Изменение статуса заказа (в CRM API или MES API). Записываем:
        timestamp
        orderId
        oldStatus → newStatus
        userId/оператор
        источник вызова (REST, message)

    Взаимодействие с 3D Files Storage (в Shop API, CRM API, MES API):
        timestamp
        fileId
        тип операции (upload/download)
        result (OK, error)

    Получение/отправка сообщения в RabbitMQ (CRM API, MES API):
        timestamp
        queue / routing key
        messageId (корреляционный ID)
        тип сообщения (createOrder, updateOrder, calcPrice и т. д.)

    Записи о входящих HTTP-запросах: метод, URL, код ответа, время обработки. (Возможно, писать в middleware/HTTP-логер.)

    Уровень загрузки (RabbitMQ, DB) можно логировать по крону или при превышении порога, но обычно это метрики. Для INFO достаточно логов об общих «событиях» (перезапуск очереди, восстановление ноды).

1.3 Другие уровни логирования

    DEBUG — детальная отладочная информация (времена исполнения отдельных методов, подробные данные запроса). Включаем на стенде dev/release, но не на проде (чтобы не захламлять логи).
    WARN — признаки потенциальной проблемы (например, сообщение в RabbitMQ лежит слишком долго, бизнес-логика близка к таймауту).
    ERROR — исключения, которые приводят к сбою в бизнес-логике (некорректная модель, невозможность сохранить файл, SQL-ошибка и т. д.).
    FATAL — если есть системная ошибка (например, выход из строя ключевой базы или полная недоступность RabbitMQ).

Обычно в продакшне оставляют INFO/WARN/ERROR. DEBUG включают точечно.
2. Мотивация
2.1 Зачем нужно логирование и что оно даст компании

    Сокращение времени на расследование инцидентов. Сейчас разработчики опрашивают клиентов и тратят много времени на ручной поиск. Наличие централизованных логов с метаданными заказов и временем операций позволит быстрее находить причину.
    Прозрачность процессов. Логи помогают ответить на вопрос «кто и когда сделал действие?», «почему заказ не перешёл в статус хххх?».
    Основа для аналитики. На базе логов можно строить отчёты: какой сервис чаще всего даёт ошибки, где узкое место.
    Предпосылка к проактивному мониторингу. При корреляции логов и метрик можно заранее увидеть тренд к ухудшению.

2.2 Технические и бизнес-метрики

    Mean Time to Detect (MTTD) — время, за которое мы узнаём об инциденте.
    Mean Time to Repair (MTTR) — время, за которое решаем проблему. С логированием оно снижается.
    Error rate в каждом сервисе (Shop, CRM, MES) — уменьшение за счёт быстрой диагностики.
    Уровень удовлетворённости клиентов — растёт при сокращении сбоёв и задержек.
    Число инцидентов, не требующих эскалации — если поддержка может самостоятельно решить проблему, без вовлечения разработчиков.

Приоритет: какие системы настраивать первыми

    MES API — самое узкое место (расчёт стоимости, частые жалобы). Логи нужны, чтобы понять, почему заказ «завис».
    CRM API — там статусы заказов, клиенты часто жалуются на пропавшие статусы.
    RabbitMQ — двунаправленный обмен, потеря сообщений наиболее критична.

Shop API, DB и 3D-хранилище — тоже важны, но обычно основные проблемы связаны с производством (MES) и статусами (CRM).
3. Предлагаемое решение
3.1 Технологии и компоненты

    Формат логов: JSON-логирование (structured logs) или обычные текстовые логи; главное, чтобы все сервисы придерживались единого формата (с обязательным timestamp, уровень логирования, correlationID, orderId).
    Библиотеки:
        Java (Shop API, CRM API): Logback + JSON encoder / Log4j2 JSON layout.
        C# (MES API): Serilog, NLog, или аналог с поддержкой структурированных логов.
        RabbitMQ: встроенные лог-файлы, плюс event-logging, audit-logging.
    Централизованное хранилище: EFK (ElasticSearch + Fluentd + Kibana) или Loki + Grafana. Можно Managed ELK в Yandex Cloud.
    Как вариант: каждый сервис пишет логи в stdout/файл → агент (Fluent Bit/Logstash/Vector) → единый index в ElasticSearch или Loki → интерфейс визуализации (Kibana/Grafana).

На схеме добавлен ещё один блок «Лог-агрегатор» (Logstash/Fluent Bit) и «Хранилище логов» (Elasticsearch/Loki), а также линии от каждого сервиса к этому агрегатору.

Диаграмма AlexandritLogs (plantuml)

Диаграмма AlexandritLogs (png)
3.2 Безопасность логов

    Сокрытие чувствительных данных (PII, пароли, токены). Логи нужно фильтровать (Logstash/Fluent Bit) перед отправкой в хранилище.
    Доступ к Kibana/Grafana только у сотрудников с соответствующей ролью (DevOps, support). Рекомендуется SSO (single sign-on).
    Шифрование канала передачи логов (TLS) от агентов к хранилищу.
    RBAC (role-based access control) для чтения/удаления логов.

3.3 Политика хранения

    Индексы по сервисам: выделить отдельные индексы (shop-api-logs, crm-api-logs, mes-api-logs и т. п.). Это облегчает поиск и разделение доступа.
    Retain logs на 14–30 дней для онлайн-доступа, более старые архивировать (S3) или удалять.
    Размер: зависит от RPS и формата логов. Важно задать квоты (max index size) и политику ротации.

4. Превращение системы сбора логов в систему анализа
4.1 Алертинг на основе логов

    Если видим всплеск ошибок (ERROR) в MES API, создаём алерт (подобно мониторингу метрик).
    Если за секунду появилось 10 000 запросов на создание заказа (DDoS-подобная активность), тоже нужен алерт.
    Интеграция с мессенджером или почтой DevOps/поддержки.

4.2 Поиск аномалий

    Механизмы Machine Learning (например, Elastic ML) или ручные правила.
    Резкий рост WARN/ERROR — потенциальный сбой.
    Необычные паттерны в логах RabbitMQ или MES API (много дубликатов заказов).

