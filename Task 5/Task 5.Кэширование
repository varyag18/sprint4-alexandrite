Кеширование
1. Мотивация.
1.1 Почему нужно кеширование?

	За счет трейсинга и логирования можноо определить места, которые могут требовать первоочередного внедрения кэширования.
    Низкая скорость работы MES. Операторы жалуются, что страница со списком заказов долго грузится, даже с учётом пагинации и фильтра. Логи и трейсинг показывают, что MES API может долго обращаться к базе данных при каждом запросе и при получении статусов заказов через RabbitMQ.
    Увеличение числа заказов. Кеширование позволит снизить нагрузку на БД и повысить скорость отклика, избежать возникновения "бутылочного горлышка".
    Частые запросы на одни и те же данные. Список заказов в определённом статусе (например, «MANUFACTURING_STARTED») может не меняться каждые 2 секунды, но операторы могут обновлять страницу, чтобы «выхватить» новые заказы.
    Ускорение отклика B2B клиентов. Партнёрские интеграции (CRM API, MES API) тоже часто делают повторные запросы о статусе и стоимости.

1.2 Какие элементы системы планируем кешировать?

    Список заказов для MES: чтобы при загрузке дашборда «заказы в работе» MES прежде всего обращался в кэш.
    Расчитанная стоимость заказа (MES): в случаях, когда MES API часто пересчитывает сложные 3D-модели. При повторных запросах мы можем временно хранить результат.
    Дополнительно: при необходимости можно кешировать статичные данные, если статистика показывает что они часто запрашиваются.

2. Предлагаемое решение
2.1 Тип кеширования

    Серверное кеширование (например, Redis в связке с MES API). Операторский интерфейс (MES фронтенд) должен работать быстро даже при большом количестве заказов. Данные должны быть в центральном кэше, а не только на машинах операторов.
    Cache-Aside. Наиболее гибкий вариант:
        Хорошо работает там где превалируют запросы на чтение.
		Приложение (MES API) сначала проверяет кеш (Redis), если данных там нет — загружает из БД, отдаёт клиенту и записывает в кеш.
        При изменении статуса (или при обновлении стоимости) приложение тоже обновляет/инвалидирует кеш.
		Если сервер кэширования выходит из строя, то система продолжает работать.
		

Почему не Write-Through или Refresh-Ahead?

    Write-Through предполагает, что каждое обновление идёт сначала в кеш, а затем в БД. Это усложняет логику и может привести к несогласованности при сбоях.
    Refresh-Ahead хорош, когда есть чёткие интервалы «прогрева кеша» — в нашем случае список заказов меняется неравномерно, а стоимость пересчитывается динамически, так что сложно предсказать, когда прогревать.

2.2 Диаграмма последовательности (Sequence Diagram)

На диаграмме отображены операция чтения списка заказов и запись об изменении статуса заказа.

см. Task 5.puml и Task 5.png.

2.3 Стратегия инвалидации кеша

Поскольку мы используем паттерн Cache-Aside, мы полагаемся на выполнения определенных программных условий инвалидации:

    Когда статус заказа меняется, MES API явно инвалидирует (или обновляет) запись в кеше, связанный со списком заказов.
    Можно также поставить TTL (time-to-live) на кешированные записи, чтобы при забытом инвалидировать, старые данные не лежали бесконечно.

Сравнение вариантов:
Вариант 1: Только программная инвалидация

    Плюсы: полный контроль, когда меняются данные, мы гарантированно чистим кеш.
    Минусы: нужно пошагово применять условия и смотреть результат.

Вариант 2: TTL + программная инвалидация

    Плюсы: даже если мы забыли где-то вызвать инвалидатор, кеш сам обновится.
    Минусы: TTl фактически является дополнительным условием и нужно следить за его корректной работой.

Мы выбираем вариант 2 (программная инвалидация + TTL). Это даёт более гибкий баланс между согласованностью (оператор сразу видит обновлённый список) и безопасностью (данные в любой случае устареют).
3. Альтернативные решения

Решение 1: Redis + Cache-Aside

    Описание: MES API работает с Redis, записывает и читает. При изменении статуса инвалидируем ключ.
    Плюсы: гибкая логика, простая реализация, не находимся в потоке обновления.
    Минусы: требует продуманного кода для кэширования и инвалидации данных вручную.

Решение 2: Внедрить HTTP-кеширование на уровне Gateway

    Описание: можно настроить NGINX/APIGateway c помощью Cache-Control.
    Плюсы: не нужно трогать внутреннюю логику MES API, часть запросов к списку заказов кэшируется.
    Минусы: плохо управлять динамическими данными (статусы заказов, которые часто меняются). Можно получить устаревшие списки.

Итог: учитывая высокую динамику данных, Решение 1 (Redis + Cache-Aside + программная инвалидация) подходит лучше, так как даёт точный контроль над актуальностью списка заказов.
Заключение

Предложенный подход с серверным кешированием (Redis) и паттерном Cache-Aside решает проблемы долгого чтения списка заказов в MES и повторных вычислений стоимости. Дополнительные детали:

    Инвалидация – программная + TTL.
    Диаграмма последовательности показывает логику чтения (Cache Miss/Hit) и обновления (инвалидируем кеш).
    Альтернативы (Write-Through, Refresh-Ahead, клиентский кеш, HTTP-кеширование) признаны менее эффективными для нашего сценария.

Таким образом, за счёт кеширования можно ускорить MES (как для операторов, так и для B2B-пользователей), уменьшить нагрузку на БД и повысить общую пропускную способность системы.
